---
title: "ML_Quiz"
author: "majusus"
date: "June 5, 2019"
output: html_document
---

###WEEK 2 QUIZ

#Question 1

##installing "caret" package
```{r results='hide'}
library(caret)
```
##loading the alzheimer disease data
```{r results='hide'}
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
```

##partitioning data in training and test data (50-50)
```{r}
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
```


#Question 2

##Loading cement data
```{r}
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
```

##plotting outcome (CompressiveStrength) versus the index of the samples
```{r}
library(GGally)
library(Hmisc)
## Using ggpair
training2 <- training
#cut CompressiveStrength into 4 levels.  This is the only way to work with colour in ggpair
training2$CompressiveStrength <- cut2(training2$CompressiveStrength, g=4)
ggpairs(data = training2, columns = c("FlyAsh","Age","CompressiveStrength")
        , mapping = ggplot2::aes(colour = CompressiveStrength))
```

#Question 3

##plotting histogram to confirm the SuperPlasticizer variable is skewed
```{r}
library(AppliedPredictiveModeling)
data(concrete)
suppressMessages(library(caret))
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
par(mfrow = c(2,1))
hist(training$Superplasticizer)
hist(log(training$Superplasticizer + 1))
```

#Question 4

##Find all the predictor variables in the training set that begin with IL 
```{r}
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]

trainingIL <- training[,grep("^IL", names(training))]
procTrain <- preProcess(trainingIL, method = "pca", thresh = 0.9 )
procTrain
```

#Question 5

##Load the Alzheimer's disease data using the commands:
```{r}
library(caret)  
library(AppliedPredictiveModeling)  
set.seed(3433)
data(AlzheimerDisease)  
adData = data.frame(diagnosis,predictors)  
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]  
testing = adData[-inTrain,]  
```

##prediction using "glm"
```{r}
# grep all columns with IL and diagnosis in the traning and testing set
trainingIL <- training[,grep("^IL|diagnosis", names(training))]
testingIL <- testing[,grep("^IL|diagnosis", names(testing))]

# non-PCA
model <- train(diagnosis ~ ., data = trainingIL, method = "glm")
predict_model <- predict(model, newdata= testingIL)
matrix_model <- confusionMatrix(predict_model, testingIL$diagnosis)
matrix_model$overall[1]
```

```{r}
# PCA
modelPCA <- train(diagnosis ~., data = trainingIL, method = "glm", preProcess = "pca",trControl=trainControl(preProcOptions=list(thresh=0.8)))
matrix_modelPCA <- confusionMatrix(testingIL$diagnosis, predict(modelPCA, testingIL))
matrix_modelPCA$overall[1]
```



###WEEK 3 QUIZ

#Question 1

##Loading cell segmentation data from the AppliedPredictiveModeling package using the commands:

```{r results='hide'}
library(AppliedPredictiveModeling)
data(segmentationOriginal)
suppressMessages(library(caret))
```

##Solution

```{r}
library(rpart)
# 1. Subset the data to a training set and testing set based on the Case variable in the data set. 
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.6, 
                               list = FALSE) # 60% training
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
# 2. Set the seed to 125 and fit a CART model with the rpart method using all predictor variables and default caret settings. (The outcome class is contained in a factor variable called Class with levels "PS" for poorly segmented and "WS" for well segmented.)
set.seed(125)
modFit <- train(Class ~ ., method = "rpart", data = training)
# 3. 
modFit$finalModel
```

```{r}
suppressMessages(library(rattle))
library(rpart.plot)
fancyRpartPlot(modFit$finalModel)
```


#Question 2

If K is small in a K-fold cross validation is the bias in the estimate of out-of-sample (test set) accuracy smaller or bigger? If K is small is the variance in the estimate of out-of-sample (test set) accuracy smaller or bigger. Is K large or small in leave one out cross validation?

##Solution: 
The bias is larger and the variance is smaller. Under leave one out cross validation K is equal to the sample size.


#Question 3

##Load the olive oil data using the commands:
```{r results='hide'}
library(pgmm)
data(olive)
olive = olive[, -1]
```

Then predict the value of area for the following data frame using the tree command with all defaults
```{r results='hide'}
newdata = as.data.frame(t(colMeans(olive)))
```

##Solution:

```{r}
modolive <- train(Area ~ ., method = "rpart", data = olive)
```

```{r}
predict(modolive, newdata = newdata)
```


#Question 3

##Load the South Africa Heart Disease Data and create training and test sets with the following code:

```{r results='hide'}
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1], size = dim(SAheart)[1] / 2, replace = F)
trainSA = SAheart[train, ]
testSA = SAheart[-train, ]
```

Calculate the misclassification rate for your model using this function and a prediction on the "response" scale:

```{r results='hide'}
missClass = function(values, prediction){sum(((prediction > 0.5) * 1) != values) / length(values)}
```

##Solution:

```{r}
set.seed(13234)
modelSA <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, 
               data = trainSA, method = "glm", family = "binomial")
missClass(testSA$chd, predict(modelSA, newdata = testSA))
```

```{r}
missClass(trainSA$chd, predict(modelSA, newdata = trainSA))
```


#Question 5

##Load the vowel.train and vowel.test data sets:

```{r results='hide'}
library(ElemStatLearn)
data(vowel.train)
data(vowel.test) 
```

Calculate the variable importance using the varImp function in the caret package. What is the order of variable importance?

##Solution:

```{r results='hide'}
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
library(randomForest)
```

```{r}
modvowel <- randomForest(y ~ ., data = vowel.train)
order(varImp(modvowel), decreasing = T)
```
