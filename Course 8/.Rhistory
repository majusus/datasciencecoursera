install.packages("devtools")
library(R6)
search()
find.packages("devtools")
find.package("devtools")
library(devtools)
find_rtools()
install.packages("pkgbuild")
install.packages("devtools")
install.packages("devtools")
library(devtools)
devtools::install_github("r-lib/pkgbuild")
library(pkgbuild)
find_rtools()
install.packages("KernSmooth")
library(KernSmooth)
0/0
1/0
1/Inf
args(lapply)
set.seed(1)
rpois(5, 2)
set.seed(10)
x <- rep(0:1, each = 5)
e <- rnorm(10, 0, 20)
y <- 0.5 + 2 * x + e
y
install.packages("RMysql")
install.packages("RMySql")
install.packages("RMySQL")
library("RMySQL")
library("DBI")
library("RMySQL")
install.packages("MikTex")
R
version
version
install.packages("MikTex")
install.packages("latex")
install.packages("ggthemes")
install.packages("devtools")
devtools::install_github("jhudsl/collegeIncome")
library(collegeIncome)
data(college)
devtools::install_github("jhudsl/matahari")
library(matahari)
dance_start(value = FALSE, contents = FALSE)
dance_save("~/Desktop/college_major_analysis.rds")
devtools::install_github("jhudsl/matahari")
library(matahari)
setwd("E:/datascience/datasciencecoursera/Course 8")
install.packages("ElemStatLearn","pgmm","rpart","gbm","lubridate","forecast",
"e1071")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
install.packages("ElemStatLearn")
install.packages("pgmm")
install.packages("rpart")
install.packages("gbm")
install.packages("lubridate")
install.packages("forecast")
install.packages("e1071")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
rfvowel <- train(y ~ ., vowel.train, method = "rf")
library(caret)
rfvowel <- train(y ~ ., vowel.train, method = "rf")
predrf <- predict(rfvowel, newdata = vowel.test)
confusionMatrix(predrf, vowel.test$y)
gbmvowel <- train(y ~ ., vowel.train, method = "gbm", verbose = FALSE)
gbmvowel <- train(y ~ ., vowel.train, method = "gbm", verbose = FALSE)
##train the data method "gbm"
library(gbm)
gbmvowel <- train(y ~ ., vowel.train, method = "gbm", verbose = FALSE)
predgbm <- predict(gbmvowel, vowel.test)
confusionMatrix(predgbm, vowel.test$y)
##compare accuracy between two methods
modelagreed <- (predrf == predgbm)
confusionMatrix(vowel.test$y[modelagreed], predrf[modelagreed])$overall['Accuracy']
confusionMatrix(predrf, vowel.test$y)$overall['Accuracy']
confusionMatrix(predgbm, vowel.test$y)$overall['Accuracy']
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
mod_rf <- train(diagnosis ~ ., training, method = "rf")
mod_gbm <- train(diagnosis ~ ., training, method = "gbm", verbose = FALSE)
mod_lda <- train(diagnosis ~ ., training, method = "lda")
rfpred <- predict(mod_rf, testing)
gbmpred <- predict(mod_gbm, testing)
ldapred <- predict(mod_lda, testing)
confusionMatrix(rfpred, testing$diagnosis)$overall['Accuracy'] ##rf
confusionMatrix(gbmpred, testing$diagnosis)$overall['Accuracy'] ##gbm
confusionMatrix(ldapred, testing$diagnosis)$overall['Accuracy'] ##lda
combine <- data.frame(rfpred, gbmpred, ldapred, diagnosis = testing$diagnosis)
mod_comb <- train(diagnosis ~ ., combine, method = "rf")
combpred <- predict(mod_comb, testing)
confusionMatrix(testing$diagnosis, combpred)$overall['Accuracy']
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
modlasso <- train(CompressiveStrength ~ ., training, method = "lasso")
##plotting
plot.enet(modlasso$finalModel, xvar="penalty", use.color=TRUE)
##plotting
library(elasticnet)
plot.enet(modlasso$finalModel, xvar="penalty", use.color=TRUE)
url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv"
download.file(url, destfile = "gaData.csv")
dat = read.csv("gaData.csv")
library(lubridate)
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
modfc <- bats(tstrain)
predts <- forecast(modfc, level = 95, nrow(testing))
fslower95 <- predts$lower
fsupper95 <- predts$upper
table ((testing$visitsTumblr>fslower95) & (testing$visitsTumblr<fsupper95))
tbl<-table ((testing$visitsTumblr>fslower95) & (testing$visitsTumblr<fsupper95))
tbl
tbl$true/nrow(testing)
tbl/nrow(testing)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
library(e1071)
set.seed(325)
fit <- svm(CompressiveStrength ~ ., training)
predsvm <- predict(fit, testing)
error = predsvm - testing$CompressiveStrength
mse <- sqrt(mean(error^2))
mse
knitr::opts_chunk$set(echo = TRUE)
library(rpart)
rpart.plot(decisionTreeMod$finalModel)
install.packages("rpart")
install.packages("rpart")
library("rpart.plot")
install.packages("rpart.plot")
library(rpart.plot)
rpart.plot(decisionTreeMod$finalModel)
unlink('Course8Assignment_cache', recursive = TRUE)
